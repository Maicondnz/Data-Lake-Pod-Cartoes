# **PoD Cart√µes - Projeto Data Lake**

## **Introdu√ß√£o**
A PoD Cart√µes √© uma empresa de cart√µes de cr√©dito que busca otimizar o uso de seus dados, por√©m enfrenta desafios devido √† fragmenta√ß√£o das informa√ß√µes em m√∫ltiplos sistemas lentos e a uma infraestrutura que n√£o suporta Big Data. Essa limita√ß√£o dificulta o consumo de dados organizados e de alta qualidade, prejudicando o desenvolvimento de modelos preditivos. Para solucionar esse problema, a empresa pretende implementar um Data Lake escal√°vel e acess√≠vel, garantindo a unifica√ß√£o, governan√ßa e seguran√ßa dos dados. Al√©m disso, ser√° desenvolvido um Book de Vari√°veis para apoiar a cria√ß√£o de modelos anal√≠ticos mais eficazes.


A solu√ß√£o utiliza servi√ßos da AWS para ingest√£o, processamento e organiza√ß√£o de dados em zonas espec√≠ficas (Raw, Trusted e Curated), al√©m de orquestra√ß√£o de pipelines com o **Apache Airflow**.

## **Dados**
![dados relacionamento](imgs/dados.jpg)


## **Arquitetura**
A arquitetura do projeto est√° ilustrada abaixo:

![arquitetura](imgs/Arquitetura.png)

## **Data Lake Zonas**

| **Zona**      | **Descri√ß√£o**                                                                                                                                                                                                                                                                          |
|---------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Ingestion** | Dados brutos coletados diretamente do sistema transacional.                                                                                                                                                          |
| **Raw**       | Dados pr√©-processados que passaram por uma limpeza e valida√ß√£o iniciais, particionados por data e armazenados em formato Parquet. Uma tabela de controle √© criada para registrar a data de processamento..                           |
| **Curated**   | Dados refinados, deduplicados e integrados, com enriquecimento por meio da cria√ß√£o de vari√°veis customizadas alinhadas aos requisitos do neg√≥cio. Essa camada inclui uma etapa pr√©-book (stage) para desenvolvimento de vari√°veis, seguida da agrega√ß√£o final conforme os per√≠odos de an√°lise e armazenamento na camada de Book para an√°lises avan√ßadas e modelagem preditiva. |
                                                                                                                
                                                                                                                
                                                                                                                
## **Servi√ßos Utilizados**

| **Servi√ßo**         | **Descri√ß√£o**                                                                                                                                                      |
|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **EC2**  |  Inst√¢ncia utilizada para executar o Apache Airflow em um ambiente Docker e a ingest√£o dos dados.                        |
| **Apache Airflow**  | Orquestra√ß√£o de pipelines de ingest√£o e transforma√ß√£o de dados, permitindo o agendamento, monitoramento e automa√ß√£o dos fluxos de trabalho.                        |
| **EMR**             | Plataforma gerenciada de Big Data que faz a execu√ß√£o dos processos ETL e an√°lises distribu√≠das, utilizando Spark                   |
| **Glue**            | Servi√ßo para cataloga√ß√£o que automatiza a descoberta dos dados armazenados no S3 para consulta e an√°lise.                             |
| **Athena**          | Servi√ßo de consulta interativa que permite executar queries SQL diretamente sobre os dados armazenados no S3, facilitando an√°lises ad hoc e gera√ß√£o de relat√≥rios. |
| **S3**              | Armazenamento escal√°vel e dur√°vel que hospeda as zonas Raw, Trusted e Curated do Data Lake.                                                                         |
| **IAM**             | Gerenciamento de identidades e acessos que assegura controles de seguran√ßa e permiss√µes adequadas aos recursos AWS.                                                   |
| **CloudWatch**      | Servi√ßo de monitoramento que coleta m√©tricas e logs da infraestrutura AWS, contribuindo para o controle de custos e desempenho.                                      |
| **Docker**          | Plataforma de cont√™ineriza√ß√£o que facilita a cria√ß√£o, implanta√ß√£o e execu√ß√£o de aplica√ß√µes em ambientes isolados e consistentes, otimizando o desenvolvimento e a integra√ß√£o. |

## **Bibliotecas**

- pandas
- pyspark
- datetime
- time
- boto3
- configparser
- os

## **DAGS**
üîπ **Todas as Dags s√£o programadas para enviar um e-mail em caso de falha nos processos.**

### **Ingest√£o**
- Respons√°vel pela extra√ß√£o de dados do SGBD e armazenamento na primeira camada do Data Lake (Ingestion).
- A DAG √© programada para executar diariamente √†s 05:00h, garantindo que os dados mais recentes sejam transferidos para o Data Lake.
  
![dag ingest√£o](imgs/dag_ingestion.jpg)
  

### **Processamento de dados por tabela**
- Esta DAG inicia um cluster EMR que executa um step job para realizar o processamento dos dados por assunto (tabelas individuais).
- Ap√≥s o processamento, o cluster √© finalizado automaticamente para evitar custos adicionais.
- Programada para executar diariamente √†s 08:00h, mantendo os dados processados atualizados.
  
![dag processamento](imgs/dag_processamento.jpg)

### **Processamento de Book**
- Focada na cria√ß√£o e atualiza√ß√£o das tabelas stage e book de vari√°veis, essenciais para an√°lises e modelos preditivos.
- A DAG sobe um cluster EMR, executa o step job e encerra o cluster ao final do processamento.
- Programada para rodar mensalmente, todo dia 01, √†s 22:00h, garantindo que os dados do book estejam preparados para an√°lises estrat√©gicas.
  
![dag book](imgs/dag_book.jpg)

## **BOOK DE VARI√ÅVEIS**

###  **STAGE**
Na etapa **Stage**, foram criadas vari√°veis para analisar o comportamento de uso do cart√£o de cr√©dito pelos clientes. As principais m√©tricas incluem:  

- **Classifica√ß√£o de Dias de Atraso**  
- **N√∫mero de Dias em Atraso**  
- **Classifica√ß√£o do Valor Pago em Rela√ß√£o √† Fatura**  
- **Porcentagem da Fatura Paga**  
- **Quantidade de Transa√ß√µes**  

---

### **BOOK**  
Na etapa **Book**, os valores num√©ricos foram agregados por classifica√ß√£o e janelas de tempo, utilizando **01/02/2024** como data de refer√™ncia.  
A an√°lise segue uma vis√£o mensal para os per√≠odos:  
**U1M, U3M, U6M, U9M e U12M** (√∫ltimos 1, 3, 6, 9 e 12 meses).  

Ao todo, foram geradas **665 vari√°veis agregadas**, organizadas conforme as seguintes categorias:  

---

##  1. Classifica√ß√£o por Prazo de Pagamento (`fbc_classificacao_dias_pagamento`)  
Define o status do pagamento com base na data de vencimento:  

- `SEM_PAGAMENTO` ‚Üí Nenhum pagamento registrado  
- `PAGAMENTO_ATRASADO` ‚Üí Pago ap√≥s o vencimento  
- `PAGAMENTO_NO_PRAZO` ‚Üí Pago exatamente no vencimento  
- `PAGAMENTO_ANTECIPADO` ‚Üí Pago antes do vencimento  

##  2. Classifica√ß√£o por Valor Pago (`fbc_classificacao_vlr_pagamento`)  
Agrupa os pagamentos conforme a propor√ß√£o do valor pago em rela√ß√£o ao total da fatura:  

- `PAGAMENTO_INSUFICIENTE` ‚Üí Pagamento menor que o m√≠nimo exigido  
- `PAGAMENTO_MINIMO` ‚Üí Pagamento exatamente no valor m√≠nimo    
- `PAGAMENTO_PARCIAL` ‚Üí Pagamento maior que o m√≠nimo, mas menor que o total  

##  3. Indicadores Financeiros Calculados (`fvls`)  
Cada m√©trica de pagamento √© analisada a partir das seguintes vari√°veis:  

-  **`fvl_valor_fatura`** ‚Üí Valor total da fatura  
-  **`fvl_valor_pagamento_minimo`** ‚Üí Valor m√≠nimo exigido  
-  **`fvl_valor_pagamento`** ‚Üí Valor efetivamente pago  
-  **`fvl_numero_dias_atraso`** ‚Üí N√∫mero de dias em atraso  
-  **`fvl_qtd_transacao`** ‚Üí Quantidade de transa√ß√µes realizadas  
-  **`fvl_pct_fatura_pgto`** ‚Üí Percentual da fatura que foi paga  

##  4. Janelas Temporais (`janelas`)  
As m√©tricas s√£o analisadas dentro das seguintes janelas de tempo:  

-  **√öltimo m√™s (`flg_u1m`)**  
-  **√öltimos 3 meses (`flg_u3m`)**  
-  **√öltimos 6 meses (`flg_u6m`)**  
-  **√öltimos 9 meses (`flg_u9m`)**  
-  **√öltimos 12 meses (`flg_u12m`)**  

##  5. M√©tricas Agregadas (`aggs`)  
Para cada vari√°vel financeira e janela temporal, s√£o aplicadas as seguintes fun√ß√µes estat√≠sticas:  

- **`SUM`** ‚Üí Soma dos valores no per√≠odo  
- **`AVG`** ‚Üí M√©dia dos valores no per√≠odo  
- **`MAX`** ‚Üí Valor m√°ximo no per√≠odo  
- **`MIN`** ‚Üí Valor m√≠nimo no per√≠odo  

---

##  6. Regras de Exclus√£o de M√©tricas  
Para garantir a coer√™ncia dos c√°lculos, algumas combina√ß√µes de m√©tricas foram desconsideradas:  

 **`fvl_numero_dias_atraso`** ‚Üí N√£o faz sentido somar dias de atraso ao longo dos meses.  

 **`fvl_qtd_transacao`** ‚Üí S√≥ pode ser somado, pois cada transa√ß√£o √© contabilizada individualmente por m√™s.  

 **`fvl_pct_fatura_pgto`** ‚Üí N√£o faz sentido somar percentuais de fatura paga ao longo dos meses.  

 **`flg_u1m`** ‚Üí Permite apenas soma (`SUM`), pois em um √∫nico m√™s, as fun√ß√µes `SUM`, `AVG`, `MAX` e `MIN` retornariam o mesmo valor.  

 **`SEM_PAGAMENTO` e `PAGAMENTO_TOTAL`** ‚Üí N√£o possuem m√©tricas de percentual pago, pois resultariam em colunas constantes.  

---
